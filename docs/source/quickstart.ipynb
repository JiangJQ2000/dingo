{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Quickstart tutorial\n",
    "\n",
    "To learn to use Dingo, we recommend starting with the examples provided in the `/examples`\n",
    "folder. The YAML files contained in this directory (and subdirectories) contain\n",
    "configuration settings for the various Dingo tasks (constructing training data, training networks, and performing inference). These files should be provided as input to the\n",
    "command-line scripts, which then run Dingo and save output files. These output files\n",
    "contain as metadata the settings in the `.yaml` files, and they may usually be inspected\n",
    "by running `dingo_ls`.\n",
    "\n",
    "```{mermaid}\n",
    "flowchart TB\n",
    "    dataset_settings[dataset_settings.yaml]\n",
    "    dataset_settings-->generate_dataset([\"dingo_generate_dataset\n",
    "    #nbsp; #nbsp; --settings_file dataset_settings.yaml\n",
    "    #nbsp; #nbsp; --out_file waveform_dataset.hdf5\"])\n",
    "    style generate_dataset text-align:left\n",
    "    asd_settings[asd_dataset_settings.yaml]\n",
    "    asd_settings-->generate_asd([\"generate_asd_dataset\n",
    "    #nbsp; #nbsp; --settings_file dataset_settings.yaml\n",
    "    #nbsp; #nbsp; --data_dir asd_dataset\"])\n",
    "    style generate_asd text-align:left\n",
    "    train_init([\"dingo_train \n",
    "    #nbsp; #nbsp; --settings_file train_settings_init.yaml\n",
    "    #nbsp; #nbsp; --train_dir model_init\"])\n",
    "    style train_init text-align:left\n",
    "    train_settings_init[train_settings_init.yaml]\n",
    "    train_settings_init-->train_init\n",
    "    generate_dataset--->train_init\n",
    "    generate_asd--->train_init\n",
    "    generate_dataset--->train_main([\"dingo_train \n",
    "    #nbsp; #nbsp; --settings_file train_settings_main.yaml\n",
    "    #nbsp; #nbsp; --train_dir model_main\"])\n",
    "    style train_main text-align:left\n",
    "    train_settings_main[train_settings_main.yaml]\n",
    "    generate_asd--->train_main\n",
    "    train_settings_main-->train_main\n",
    "    train_init-->inference([\"dingo_analyze_event\n",
    "    #nbsp; #nbsp; --model model_main/model_stage_1.pt\n",
    "    #nbsp; #nbsp; --model_init model_init/model_stage_1.pt\n",
    "    #nbsp; #nbsp; --num_samples 50000\n",
    "    #nbsp; #nbsp; --gps_time_event 1126259462.4\"])\n",
    "    style inference text-align:left\n",
    "    train_main-->inference\n",
    "    inference-->samples[dingo_samples-1126259462.4.hdf5]\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "After configuring the settings files, the scripts may be used as follows, assuming the\n",
    "Dingo `venv` is active.\n",
    "\n",
    "## Generate training data\n",
    "\n",
    "### Waveforms\n",
    "\n",
    "To generate a waveform dataset for training, execute\n",
    "\n",
    "```\n",
    "dingo_generate_dataset --settings_file waveform_dataset_settings.yaml --num_processes N --out_file waveform_dataset.hdf5\n",
    "```\n",
    "\n",
    "where `N` is the number of processes you would like to use to generate the waveforms in\n",
    "parallel. This saves the dataset of waveform polarizations in the\n",
    "file `waveform_dataset.hdf5` (typically compressed using SVD, depending on configuration).\n",
    "\n",
    "One can use `dingo_generate_dataset_dag` to set up a condor DAG for generating waveforms\n",
    "on a cluster. This is typically useful for slower waveform models.\n",
    "\n",
    "### Noise ASDs\n",
    "\n",
    "Training also requires a dataset of noise ASDs, which are sampled randomly for each\n",
    "training sample. To generate this dataset based on noise observed during a run, execute\n",
    "\n",
    "```\n",
    "dingo_generate_ASD_dataset --data_dir data_dir --settings_file asd_dataset_settings.yaml\n",
    "```\n",
    "\n",
    "This will download data from the GWOSC website and create a `/tmp` directory, in which the\n",
    "estimated PSDs are stored. Subsequently, these are collected together into a final `.hdf5`\n",
    "ASD dataset.\n",
    "If no `settings_file` is passed, the script will attempt to use the default\n",
    "one `data_dir/asd_dataset_settings.yaml`.\n",
    "\n",
    "## Training\n",
    "\n",
    "With a waveform dataset and ASD dataset(s), one can train a neural network. Configure\n",
    "the `train_settings.yaml` file to point to these datasets, and run\n",
    "\n",
    "```\n",
    "dingo_train --settings_file train_settings.yaml --train_dir train_dir\n",
    "```\n",
    "\n",
    "This will configure the network, train it, and store checkpoints, a record of the history,\n",
    "and the final network in the directory `train_dir`. Alternatively, to resume training from\n",
    "a checkpoint file, run\n",
    "\n",
    "```\n",
    "dingo_train --checkpoint model.pt --train_dir train_dir\n",
    "```\n",
    "\n",
    "If using CUDA on a machine with several GPUs, be sure to first select the desired GPU\n",
    "number using the `CUDA_VISIBLE_DEVICES` environment variable. If using a cluster, Dingo\n",
    "can be trained using `dingo_train_condor`.\n",
    "\n",
    "Example training files can be found under `examples/training`. There are a few .yaml files.\n",
    "`train_settings_toy.yaml` and `train_settings_production.yaml` train a flow to\n",
    "estimate the full posterior of the event conditioned on the time of coalescence\n",
    "in the detectors. The \"toy\" label is to indicate this should be used for production but \n",
    "rather only to get a feel for the Dingo pipeline. The production settings contain tested \n",
    "settings. Note that depending on the waveform model and event, these may need to occasionally\n",
    "be tuned. `train_settings_init_toy.yaml` and `train_settings_init_production.yaml` train\n",
    "flows to estimate the time of coalescence in the individual detectors. These two\n",
    "networks are needed to use [**GNPE**](gnpe.md). This is is the preferred and\n",
    "most tested way of using Dingo. \n",
    "\n",
    "Alternatively, the `train_settings_no_gnpe_toy.yaml` and\n",
    "`train_settings_no_gnpe_production.yaml` contain settings to train a network\n",
    "without the GNPE step. Note the lack of a `data/gnpe_time_shifts` option. While this is not\n",
    "recommended for production, it is still pedagogically useful and offers some flexibility.  \n",
    "\n",
    "## Inference\n",
    "\n",
    "Once a Dingo model is trained, inference for real events can be performed using\n",
    "[**dingo_pipe**](dingo_pipe.md). There are 3 main inference steps, downloading the data, \n",
    "running Dingo on this data and finally running importance sampling. The basic\n",
    "idea is to create a .ini file which contains the filepaths of the Dingo networks\n",
    "trained above and the segment of data to analyze. An example .ini file can be\n",
    "found under `examples/pipe/GW150914.ini`. \n",
    "\n",
    "To do inference, cd into the directory with the .ini file and run \n",
    "\n",
    "```\n",
    "dingo_pipe GW150914.ini\n",
    "```\n",
    "\n",
    "\n",
    "One can also separate out these steps with the CLI. First one would generate a proposal\n",
    "using:\n",
    "\n",
    "```\n",
    "dingo_analyze_event\n",
    "  --model model\n",
    "  --model_init model_init\n",
    "  --gps_time_event gps_time_event\n",
    "  --num_samples num_samples\n",
    "  --num_gnpe_iterations num_gnpe_iterations\n",
    "  --batch_size batch_size\n",
    "```\n",
    "\n",
    "where model.pt is the path of the trained Dingo mode, gps_time_event is the GPS\n",
    "time of the event to be analyzed (e.g., 1126259462.4 for GW150914), num_samples\n",
    "is the number of desired samples and batch_size is the batch size (the larger\n",
    "the faster the computation, but limited by GPU memory). Dingo downloads the\n",
    "event data from GWOSC. It also estimates the noise ASD from data prior to the\n",
    "event.\n",
    "\n",
    "Then one can do importance sampling by running \n",
    "\n",
    "`python dingo/gw/importance_sampling/importance_weights.py --settings is_settings.yaml`\n",
    "\n",
    "where `is_settings.yaml` contains the settings, and in particular points to the output\n",
    "file that was previously generated by Dingo.\n",
    "\n",
    "\n",
    "# Running inference on an injection \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
